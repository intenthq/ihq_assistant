{
  "title": "Adds messages history",
  "description": null,
  "author": "javierpedreira",
  "created_at": "2025-03-04T15:10:14Z",
  "changed_files": [
    {
      "filename": "slack_faiss_bot.py",
      "patch": "@@ -6,12 +6,15 @@\n from slack_bolt.adapter.socket_mode import SocketModeHandler\n from dotenv import load_dotenv\n import logging\n+from collections import deque\n from langchain_community.docstore.in_memory import InMemoryDocstore\n from langchain_community.vectorstores import FAISS\n from langchain import hub\n from langchain.chat_models import init_chat_model\n from langchain.embeddings import OpenAIEmbeddings\n from faiss import IndexFlatL2\n+from langchain.chains import LLMChain\n+from langchain.prompts import PromptTemplate\n \n # Load environment variables from .env file\n load_dotenv()\n@@ -20,19 +23,19 @@\n print(\"SLACK_APP_TOKEN:\", os.getenv(\"SLACK_APP_TOKEN\"))\n print(\"OPENAI_API_KEY:\", os.getenv(\"OPENAI_API_KEY\"))\n \n-# # Define API Keys and Tokens from environment variables\n+# Define API Keys and Tokens from environment variables\n SLACK_BOT_TOKEN = os.getenv(\"SLACK_BOT_TOKEN\")\n SLACK_APP_TOKEN = os.getenv(\"SLACK_APP_TOKEN\")\n OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n \n-\n-\n # Configure OpenAI API Key\n openai.api_key = OPENAI_API_KEY\n \n # Enable debug logging\n logging.basicConfig(level=logging.DEBUG)\n \n+# Memory storage for last 5 mentions\n+mention_memory = {}  # Key: channel_id, Value: deque of last 5 mentions\n \n # Generate OpenAI embeddings for documents\n def get_embedding(text):\n@@ -41,36 +44,54 @@ def get_embedding(text):\n     )\n     return np.array(response.data[0].embedding, dtype=np.float32)\n \n-\n # Initialize Slack App\n app = App(token=SLACK_BOT_TOKEN)\n \n # Function to search FAISS\n-def search_faiss(query):\n+def search_faiss(query, channel_id):\n     embeddings = OpenAIEmbeddings()\n-    faiss = FAISS(embedding_function=embeddings, index=IndexFlatL2, docstore=InMemoryDocstore(), index_to_docstore_id={})    \n+    faiss = FAISS(embedding_function=embeddings, index=IndexFlatL2, docstore=InMemoryDocstore(), index_to_docstore_id={})\n     db = faiss.load_local(folder_path=\"./db/coda_linear_github_embeddings.db\", embeddings=embeddings, allow_dangerous_deserialization=True)\n-    \n+\n     docs = db.similarity_search(query, k=3)\n     logging.debug(f\"Len docs: {len(docs)}\")\n-      \n+\n     docs_content = \"\\n\\n\".join(doc.page_content for doc in docs)\n     logging.debug(f\"Doc sources: {';'.join([d.metadata['source'] for d in docs])}\")\n-    prompt = hub.pull(\"rlm/rag-prompt\")\n \n+    # Retrieve last 5 messages from memory for this channel\n+    chat_history = \"\\n\".join(mention_memory.get(channel_id, []))\n+    logging.debug(f\"ðŸ”¹ Chat History for channel {channel_id}: {chat_history}\")\n \n     llm = init_chat_model(\"gpt-4\", model_provider=\"openai\")\n-    response = llm.invoke(prompt.invoke({\"question\": query, \"context\": docs_content}))\n-    \n-    return response.content\n+    prompt_template = PromptTemplate(\n+        input_variables=[\"chat_history\", \"question\", \"context\"],\n+        template=\"{chat_history}\\nUser: {question}\\nContext: {context}\\nAssistant:\"\n+    )\n+    chain = LLMChain(llm=llm, prompt=prompt_template)\n+\n+    response = chain.run(chat_history=chat_history, question=query, context=docs_content)\n+\n+    return response  # Fix: LLMChain outputs a string, no need for `.content`\n+\n+# Function to store last 5 mentions per channel\n+def store_mention(channel_id, mention_text):\n+    if channel_id not in mention_memory:\n+        mention_memory[channel_id] = deque(maxlen=10)\n+    mention_memory[channel_id].append(mention_text)\n+    logging.debug(f\"ðŸ”¹ Updated memory for channel {channel_id}: {list(mention_memory[channel_id])}\")\n \n # Slack bot listens for messages that mention it\n @app.event(\"app_mention\")\n def handle_mention(event, say):\n     logging.debug(f\"ðŸ”¹ Received mention event: {event}\")  # Debugging log\n     user_query = event[\"text\"]\n-    best_match = search_faiss(user_query)\n+    channel_id = event[\"channel\"]\n+    \n+    store_mention(channel_id, user_query)  # Store the mention\n+    best_match = search_faiss(user_query, channel_id)\n     logging.debug(f\"ðŸ”¹ Best FAISS match: {best_match}\")\n+    \n     say(f\"Best Match: {best_match}\")\n \n # Start the Slack bot using Socket Mode"
    }
  ],
  "reviews": [
    {
      "user": "cdagraca",
      "state": "APPROVED",
      "body": ""
    }
  ],
  "linked_issues": "No linked issues",
  "readme": "# Install dependencies\n\nRun\n\n```\npip3 install -r ./requirements.txt\n```\n\n# Start the bot\n\nCopy `.env.template` to `.env`, fill the tokens with real tokens\n\nCreate venv\n\n```\npython3 -m venv venv\nsource venv/bin/activate\n```\n\nRun\n\n```\npython3 slack_faiss_bot.py\n```\n"
}