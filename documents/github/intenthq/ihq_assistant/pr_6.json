{
  "title": "tidy up execute_query params",
  "description": null,
  "author": "cdagraca",
  "created_at": "2025-03-04T16:02:12Z",
  "changed_files": [
    {
      "filename": "db/linear_embeddings.db/index.faiss",
      "patch": ""
    },
    {
      "filename": "db/linear_embeddings.db/index.pkl",
      "patch": ""
    },
    {
      "filename": "load_vector_db.py",
      "patch": "@@ -4,10 +4,11 @@\n from langchain_community.docstore.in_memory import InMemoryDocstore\n from langchain_community.vectorstores import FAISS\n from langchain.embeddings import OpenAIEmbeddings\n+from typing import Optional\n \n \n # These functions assume os.environ[\"OPENAI_API_KEY\"] is set\n-def load_embeddings(source_path:str = \"coda_linear_github_embeddings.db\"):\n+def load_embeddings(source_path: str = \"coda_linear_github_embeddings.db\"):\n     embeddings = OpenAIEmbeddings()\n     faiss = FAISS(embedding_function=embeddings,\n                   index=IndexFlatL2,\n@@ -18,9 +19,9 @@ def load_embeddings(source_path:str = \"coda_linear_github_embeddings.db\"):\n                             allow_dangerous_deserialization=True)\n \n \n-def execute_query(question: str, embeddings:list = None, model:str = \"gpt-4\"):\n-    if embeddings is not None and len(embeddings) > 0:\n-        docs = embeddings.similarity_search(query=question, k=3)\n+def execute_query(question: str, embeddings_db: Optional[FAISS] = None, model: str = \"gpt-4\"):\n+    if embeddings_db is not None:\n+        docs = embeddings_db.similarity_search(query=question, k=3)\n         docs_content = \"\\n\\n\".join(doc.page_content for doc in docs)\n     else:\n         docs_content = \"\""
    },
    {
      "filename": "vectorise_data.py",
      "patch": "@@ -21,7 +21,7 @@\n         if folder == \"coda\":\n             # Strip out the encoded images\n             for d in data:\n-                d.page_content = re.sub(\"(\\[|\\()data:image.+(\\]|\\))\", \"\", d.page_content)\n+                d.page_content = re.sub(\"[\\[\\(]data:image.+[\\]\\)]\", \"\", d.page_content)\n         docs += text_splitter.split_documents(data)\n \n embeddings = OpenAIEmbeddings()"
    }
  ],
  "reviews": [
    {
      "user": "javierpedreira",
      "state": "APPROVED",
      "body": ""
    }
  ],
  "linked_issues": "No linked issues",
  "readme": "# Install dependencies\n\nRun\n\n```\npip3 install -r ./requirements.txt\n```\n\n# Start the bot\n\nCopy `.env.template` to `.env`, fill the tokens with real tokens\n\nCreate venv\n\n```\npython3 -m venv venv\nsource venv/bin/activate\n```\n\nRun\n\n```\npython3 slack_faiss_bot.py\n```\n"
}