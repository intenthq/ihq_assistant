{
  "title": "Added function calling to create linear ticket and removed langchain â€¦",
  "description": "â€¦logic to openai",
  "author": "geo-harrison",
  "created_at": "2025-03-04T17:36:25Z",
  "changed_files": [
    {
      "filename": "llm_tools.py",
      "patch": "@@ -0,0 +1,102 @@\n+import os\n+import json\n+import requests\n+from openai import OpenAI\n+\n+# Define the function to create a Linear ticket\n+def create_linear_ticket(title: str, description: str, priority: int, linear_api_key: str) -> dict:\n+    \"\"\"\n+    Creates a new Linear ticket using the given title, description, and priority.\n+\n+    Args:\n+        title (str): The title of the Linear ticket.\n+        description (str): A detailed description of the ticket.\n+        priority (int): Priority level (0 = No priority, 1 = Low, 2 = Medium, 3 = High, 4 = Urgent).\n+\n+    Returns:\n+        dict: A dictionary containing ticket details formatted for Linear API.\n+    \"\"\"\n+    TEAM_ID = '16b9a385-762f-47b0-b5d8-73ece3125bd9'\n+    API_URL = 'https://api.linear.app/graphql'\n+    headers = {\n+        'Authorization': linear_api_key,\n+        'Content-Type': 'application/json'\n+    }\n+\n+    issue_data = {\n+        \"title\": title,\n+        \"description\": description,\n+        \"teamId\": TEAM_ID,\n+        \"priority\": priority\n+    }\n+\n+    # GraphQL mutation for creating an issue\n+    mutation = \"\"\"\n+    mutation CreateIssue($input: IssueCreateInput!) {\n+      issueCreate(input: $input) {\n+        success\n+        issue {\n+          id\n+          title\n+          description\n+          url\n+        }\n+      }\n+    }\n+    \"\"\"\n+\n+    # Make the API request\n+    response = requests.post(\n+        API_URL,\n+        json={\"query\": mutation, \"variables\": {\"input\": issue_data}},\n+        headers=headers\n+    )\n+\n+    if response.status_code == 200:\n+        data = response.json()\n+        if data.get('data', {}).get('issueCreate', {}).get('success'):\n+            issue = data['data']['issueCreate']['issue']\n+            return {\n+                \"success\": True,\n+                \"issue\": {\n+                    \"id\": issue['id'],\n+                    \"title\": issue['title'],\n+                    \"description\": issue['description'],\n+                    \"url\": issue['url']\n+                }\n+            }\n+        else:\n+            return {\"success\": False, \"error\": \"Issue creation failed.\"}\n+    else:\n+        return {\"success\": False, \"error\": response.text}\n+\n+# Define the function specification for OpenAI\n+tools = [\n+    {\n+        \"type\": \"function\",  # Specify the type as 'function'\n+        \"function\": {\n+            \"name\": \"create_linear_ticket\",\n+            \"description\": \"Creates a new Linear ticket with the given title, description, and priority.\",\n+            \"parameters\": {\n+                \"type\": \"object\",\n+                \"properties\": {\n+                    \"title\": {\n+                        \"type\": \"string\",\n+                        \"description\": \"The title of the Linear ticket\"\n+                    },\n+                    \"description\": {\n+                        \"type\": \"string\",\n+                        \"description\": \"A detailed description of the issue or task.\"\n+                    },\n+                    \"priority\": {\n+                        \"type\": \"integer\",\n+                        \"description\": \"The priority level of the issue. (0 = No priority, 1 = Low, 2 = Medium, 3 = High, 4 = Urgent)\",\n+                        \"enum\": [0, 1, 2, 3, 4]\n+                    }\n+                },\n+                \"required\": [\"title\", \"description\", \"priority\"]\n+            }\n+        }\n+    }\n+]\n+"
    },
    {
      "filename": "slack_faiss_bot.py",
      "patch": "@@ -1,4 +1,5 @@\n import os\n+import json\n import faiss\n import numpy as np\n import openai\n@@ -16,6 +17,9 @@\n from langchain.chains import LLMChain\n from langchain.prompts import PromptTemplate\n \n+from openai import OpenAI\n+from llm_tools import create_linear_ticket, tools \n+\n # Load environment variables from .env file\n load_dotenv()\n \n@@ -27,9 +31,12 @@\n SLACK_BOT_TOKEN = os.getenv(\"SLACK_BOT_TOKEN\")\n SLACK_APP_TOKEN = os.getenv(\"SLACK_APP_TOKEN\")\n OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n+LINEAR_API_KEY = os.environ.get(\"LINEAR_API_KEY\")\n+OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n \n # Configure OpenAI API Key\n openai.api_key = OPENAI_API_KEY\n+client = OpenAI()\n \n # Enable debug logging\n logging.basicConfig(level=logging.DEBUG)\n@@ -47,6 +54,40 @@ def get_embedding(text):\n # Initialize Slack App\n app = App(token=SLACK_BOT_TOKEN)\n \n+def parse_chat_history(chat_history_raw):\n+    chat_history = []\n+    for message in chat_history_raw:\n+        chat_history.append({\"role\": \"user\", \"content\": message})\n+    return chat_history\n+\n+def get_prompt_messages(chat_history, question, context):\n+    messages = [\n+        {\"role\": \"developer\", \"content\": \"You are a helpful assistant.\"}, # update this system prompt more\n+    ]\n+    messages.extend(chat_history)\n+    messages.extend({\"role\": \"developer\", \"content\": f\"This is the relevant context for you to answer the users query: {context}\"})\n+    messages.extend({\"role\": \"user\", \"content\": question})\n+    return messages\n+\n+def chat_openai(messages, tools, model=\"gpt-4o-mini\"):\n+    response = client.chat.completions.create(\n+        model=model,\n+        messages=messages,\n+        tools=tools\n+    )\n+    return response.choices[0].message\n+\n+def implement_linear_function(function_args):\n+    function_args = json.loads(function_args)\n+    result = create_linear_ticket(\n+        title=function_args.get(\"title\"),\n+        description=function_args.get(\"description\"),\n+        priority=function_args.get(\"priority\"),\n+        linear_api_key=LINEAR_API_KEY\n+    )\n+    second_message = f\"A ticket as been created here: {result['issue']['url']}\"\n+    return second_message\n+\n # Function to search FAISS\n def search_faiss(query, channel_id):\n     embeddings = OpenAIEmbeddings()\n@@ -60,17 +101,22 @@ def search_faiss(query, channel_id):\n     logging.debug(f\"Doc sources: {';'.join([d.metadata['source'] for d in docs])}\")\n \n     # Retrieve last 5 messages from memory for this channel\n-    chat_history = \"\\n\".join(mention_memory.get(channel_id, []))\n+    # chat_history = \"\\n\".join(mention_memory.get(channel_id, []))\n+    chat_history = mention_memory.get(channel_id, [])\n+    chat_history = parse_chat_history(chat_history)\n     logging.debug(f\"ðŸ”¹ Chat History for channel {channel_id}: {chat_history}\")\n \n-    llm = init_chat_model(\"gpt-4\", model_provider=\"openai\")\n-    prompt_template = PromptTemplate(\n-        input_variables=[\"chat_history\", \"question\", \"context\"],\n-        template=\"{chat_history}\\nUser: {question}\\nContext: {context}\\nAssistant:\"\n-    )\n-    chain = LLMChain(llm=llm, prompt=prompt_template)\n-\n-    response = chain.run(chat_history=chat_history, question=query, context=docs_content)\n+    messages = get_prompt_messages(chat_history, query, docs_content)\n+    response = chat_openai(messages, tools)\n+\n+    if response.tool_calls != None:\n+        function_name = response.tool_calls[0].function.name\n+        function_args = response.tool_calls[0].function.arguments\n+        if function_name == \"create_linear_ticket\":\n+            try:\n+                response = implement_linear_function(function_args)\n+            except:\n+                response = \"Sorry failed to create a ticket (still learning!) - can you ask again?\"\n \n     return response  # Fix: LLMChain outputs a string, no need for `.content`\n "
    }
  ],
  "reviews": [],
  "linked_issues": "No linked issues",
  "readme": "# Install dependencies\n\nRun\n\n```\npip3 install -r ./requirements.txt\n```\n\n# Start the bot\n\nCopy `.env.template` to `.env`, fill the tokens with real tokens\n\nCreate venv\n\n```\npython3 -m venv venv\nsource venv/bin/activate\n```\n\nRun\n\n```\npython3 slack_faiss_bot.py\n```\n"
}